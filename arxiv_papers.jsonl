{"doc_id": "2509.16203v1", "title": "Inverting Trojans in LLMs", "abstract": "While effective backdoor detection and inversion schemes have been developed for AIs used e.g. for images, there are challenges in \"porting\" these methods to LLMs. First, the LLM input space is discrete, which precludes gradient-based search over this space, central to many backdoor inversion methods. Second, there are ~30,000^k k-tuples to consider, k the token-length of a putative trigger. Third, for LLMs there is the need to blacklist tokens that have strong marginal associations with the putative target response (class) of an attack, as such tokens give false detection signals. However, good blacklists may not exist for some domains. We propose a LLM trigger inversion approach with three key components: i) discrete search, with putative triggers greedily accreted, starting from a select list of singletons; ii) implicit blacklisting, achieved by evaluating the average cosine similarity, in activation space, between a candidate trigger and a small clean set of samples from the putative target class; iii) detection when a candidate trigger elicits high misclassifications, and with unusually high decision confidence. Unlike many recent works, we demonstrate that our approach reliably detects and successfully inverts ground-truth backdoor trigger phrases.", "authors": ["Zhengxing Li", "Guangmingmei Yang", "Jayaram Raghuram", "David J. Miller", "George Kesidis"], "published_date": "2025-09-19T17:59:57Z", "url": "http://arxiv.org/abs/2509.16203v1", "pdf_url": "http://arxiv.org/pdf/2509.16203v1", "primary_category": "cs.LG"}
{"doc_id": "2509.16189v1", "title": "Latent learning: episodic memory complements parametric learning by   enabling flexible reuse of experiences", "abstract": "When do machine learning systems fail to generalize, and what mechanisms could improve their generalization? Here, we draw inspiration from cognitive science to argue that one weakness of machine learning systems is their failure to exhibit latent learning -- learning information that is not relevant to the task at hand, but that might be useful in a future task. We show how this perspective links failures ranging from the reversal curse in language modeling to new findings on agent-based navigation. We then highlight how cognitive science points to episodic memory as a potential part of the solution to these issues. Correspondingly, we show that a system with an oracle retrieval mechanism can use learning experiences more flexibly to generalize better across many of these challenges. We also identify some of the essential components for effectively using retrieval, including the importance of within-example in-context learning for acquiring the ability to use information across retrieved examples. In summary, our results illustrate one possible contributor to the relative data inefficiency of current machine learning systems compared to natural intelligence, and help to understand how retrieval methods can complement parametric learning to improve generalization.", "authors": ["Andrew Kyle Lampinen", "Martin Engelcke", "Yuxuan Li", "Arslan Chaudhry", "James L. McClelland"], "published_date": "2025-09-19T17:49:25Z", "url": "http://arxiv.org/abs/2509.16189v1", "pdf_url": "http://arxiv.org/pdf/2509.16189v1", "primary_category": "cs.LG"}
{"doc_id": "2509.16186v1", "title": "Quantum Generative Adversarial Autoencoders: Learning latent   representations for quantum data generation", "abstract": "In this work, we introduce the Quantum Generative Adversarial Autoencoder (QGAA), a quantum model for generation of quantum data. The QGAA consists of two components: (a) Quantum Autoencoder (QAE) to compress quantum states, and (b) Quantum Generative Adversarial Network (QGAN) to learn the latent space of the trained QAE. This approach imparts the QAE with generative capabilities. The utility of QGAA is demonstrated in two representative scenarios: (a) generation of pure entangled states, and (b) generation of parameterized molecular ground states for H$_2$ and LiH. The average errors in the energies estimated by the trained QGAA are 0.02 Ha for H$_2$ and 0.06 Ha for LiH in simulations upto 6 qubits. These results illustrate the potential of QGAA for quantum state generation, quantum chemistry, and near-term quantum machine learning applications.", "authors": ["Naipunnya Raj", "Rajiv Sangle", "Avinash Singh", "Krishna Kumar Sabapathy"], "published_date": "2025-09-19T17:45:14Z", "url": "http://arxiv.org/abs/2509.16186v1", "pdf_url": "http://arxiv.org/pdf/2509.16186v1", "primary_category": "quant-ph"}
