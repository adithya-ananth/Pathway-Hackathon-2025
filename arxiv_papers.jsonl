{"doc_id": "2407.21059v1", "title": "Modular RAG: Transforming RAG Systems into LEGO-like Reconfigurable   Frameworks", "abstract": "Retrieval-augmented Generation (RAG) has markedly enhanced the capabilities of Large Language Models (LLMs) in tackling knowledge-intensive tasks. The increasing demands of application scenarios have driven the evolution of RAG, leading to the integration of advanced retrievers, LLMs and other complementary technologies, which in turn has amplified the intricacy of RAG systems. However, the rapid advancements are outpacing the foundational RAG paradigm, with many methods struggling to be unified under the process of \"retrieve-then-generate\". In this context, this paper examines the limitations of the existing RAG paradigm and introduces the modular RAG framework. By decomposing complex RAG systems into independent modules and specialized operators, it facilitates a highly reconfigurable framework. Modular RAG transcends the traditional linear architecture, embracing a more advanced design that integrates routing, scheduling, and fusion mechanisms. Drawing on extensive research, this paper further identifies prevalent RAG patterns-linear, conditional, branching, and looping-and offers a comprehensive analysis of their respective implementation nuances. Modular RAG presents innovative opportunities for the conceptualization and deployment of RAG systems. Finally, the paper explores the potential emergence of new operators and paradigms, establishing a solid theoretical foundation and a practical roadmap for the continued evolution and practical deployment of RAG technologies.", "authors": ["Yunfan Gao", "Yun Xiong", "Meng Wang", "Haofen Wang"], "published_date": "2024-07-26T03:45:30Z", "url": "http://arxiv.org/abs/2407.21059v1", "pdf_url": "http://arxiv.org/pdf/2407.21059v1", "primary_category": "cs.CL"}
{"doc_id": "2501.00353v1", "title": "RAG-Instruct: Boosting LLMs with Diverse Retrieval-Augmented   Instructions", "abstract": "Retrieval-Augmented Generation (RAG) has emerged as a key paradigm for enhancing large language models (LLMs) by incorporating external knowledge. However, current RAG methods face two limitations: (1) they only cover limited RAG scenarios. (2) They suffer from limited task diversity due to the lack of a general RAG dataset. To address these limitations, we propose RAG-Instruct, a general method for synthesizing diverse and high-quality RAG instruction data based on any source corpus. Our approach leverages (1) five RAG paradigms, which encompass diverse query-document relationships, and (2) instruction simulation, which enhances instruction diversity and quality by utilizing the strengths of existing instruction datasets. Using this method, we construct a 40K instruction dataset from Wikipedia, comprehensively covering diverse RAG scenarios and tasks. Experiments demonstrate that RAG-Instruct effectively enhances LLMs' RAG capabilities, achieving strong zero-shot performance and significantly outperforming various RAG baselines across a diverse set of tasks. RAG-Instruct is publicly available at https://github.com/FreedomIntelligence/RAG-Instruct.", "authors": ["Wanlong Liu", "Junying Chen", "Ke Ji", "Li Zhou", "Wenyu Chen", "Benyou Wang"], "published_date": "2024-12-31T09:00:51Z", "url": "http://arxiv.org/abs/2501.00353v1", "pdf_url": "http://arxiv.org/pdf/2501.00353v1", "primary_category": "cs.CL"}
{"doc_id": "2505.13006v1", "title": "Evaluating the Performance of RAG Methods for Conversational AI in the   Airport Domain", "abstract": "Airports from the top 20 in terms of annual passengers are highly dynamic environments with thousands of flights daily, and they aim to increase the degree of automation. To contribute to this, we implemented a Conversational AI system that enables staff in an airport to communicate with flight information systems. This system not only answers standard airport queries but also resolves airport terminology, jargon, abbreviations, and dynamic questions involving reasoning. In this paper, we built three different Retrieval-Augmented Generation (RAG) methods, including traditional RAG, SQL RAG, and Knowledge Graph-based RAG (Graph RAG). Experiments showed that traditional RAG achieved 84.84% accuracy using BM25 + GPT-4 but occasionally produced hallucinations, which is risky to airport safety. In contrast, SQL RAG and Graph RAG achieved 80.85% and 91.49% accuracy respectively, with significantly fewer hallucinations. Moreover, Graph RAG was especially effective for questions that involved reasoning. Based on our observations, we thus recommend SQL RAG and Graph RAG are better for airport environments, due to fewer hallucinations and the ability to handle dynamic questions.", "authors": ["Yuyang Li", "Philip J. M. Kerbusch", "Raimon H. R. Pruim", "Tobias K\u00e4fer"], "published_date": "2025-05-19T11:46:30Z", "url": "http://arxiv.org/abs/2505.13006v1", "pdf_url": "http://arxiv.org/pdf/2505.13006v1", "primary_category": "cs.CL"}
{"doc_id": "2506.09542v1", "title": "KG-Infused RAG: Augmenting Corpus-Based RAG with External Knowledge   Graphs", "abstract": "Retrieval-Augmented Generation (RAG) improves factual accuracy by grounding responses in external knowledge. However, existing methods typically rely on a single source, either unstructured text or structured knowledge. Moreover, they lack cognitively inspired mechanisms for activating relevant knowledge. To address these issues, we propose KG-Infused RAG, a framework that integrates KGs into RAG systems to implement spreading activation, a cognitive process that enables concept association and inference. KG-Infused RAG retrieves KG facts, expands the query accordingly, and enhances generation by combining corpus passages with structured facts, enabling interpretable, multi-source retrieval grounded in semantic structure. We further improve KG-Infused RAG via preference learning on sampled key stages in the pipeline. Experiments on five QA benchmarks show that KG-Infused RAG consistently outperforms vanilla RAG (by 3.8% to 13.8%). Additionally, when integrated into Self-RAG, KG-Infused RAG brings further performance gains, demonstrating its effectiveness and versatility as a plug-and-play enhancement module for corpus-based RAG methods.", "authors": ["Dingjun Wu", "Yukun Yan", "Zhenghao Liu", "Zhiyuan Liu", "Maosong Sun"], "published_date": "2025-06-11T09:20:02Z", "url": "http://arxiv.org/abs/2506.09542v1", "pdf_url": "http://arxiv.org/pdf/2506.09542v1", "primary_category": "cs.CL"}
{"doc_id": "2508.13828v1", "title": "Revisiting RAG Ensemble: A Theoretical and Mechanistic Analysis of   Multi-RAG System Collaboration", "abstract": "Retrieval-Augmented Generation (RAG) technology has been widely applied in recent years. However, despite the emergence of various RAG frameworks, a single RAG framework still cannot adapt well to a broad range of downstream tasks. Therefore, how to leverage the advantages of multiple RAG systems has become an area worth exploring. To address this issue, we have conducted a comprehensive and systematic investigation into ensemble methods based on RAG systems. Specifically, we have analyzed the RAG ensemble framework from both theoretical and mechanistic analysis perspectives. From the theoretical analysis, we provide the first explanation of the RAG ensemble framework from the perspective of information entropy. In terms of mechanism analysis, we have explored the RAG ensemble framework from both the pipeline and module levels. We carefully select four different pipelines (Branching, Iterative, Loop, and Agentic) and three different modules (Generator, Retriever, and Reranker) to solve seven different research questions. The experiments show that aggregating multiple RAG systems is both generalizable and robust, whether at the pipeline level or the module level. Our work lays the foundation for similar research on the multi-RAG system ensemble.", "authors": ["Yifei Chen", "Guanting Dong", "Yutao Zhu", "Zhicheng Dou"], "published_date": "2025-08-19T13:38:54Z", "url": "http://arxiv.org/abs/2508.13828v1", "pdf_url": "http://arxiv.org/pdf/2508.13828v1", "primary_category": "cs.AI"}
{"doc_id": "2501.05249v1", "title": "RAG-WM: An Efficient Black-Box Watermarking Approach for   Retrieval-Augmented Generation of Large Language Models", "abstract": "In recent years, tremendous success has been witnessed in Retrieval-Augmented Generation (RAG), widely used to enhance Large Language Models (LLMs) in domain-specific, knowledge-intensive, and privacy-sensitive tasks. However, attackers may steal those valuable RAGs and deploy or commercialize them, making it essential to detect Intellectual Property (IP) infringement. Most existing ownership protection solutions, such as watermarks, are designed for relational databases and texts. They cannot be directly applied to RAGs because relational database watermarks require white-box access to detect IP infringement, which is unrealistic for the knowledge base in RAGs. Meanwhile, post-processing by the adversary's deployed LLMs typically destructs text watermark information. To address those problems, we propose a novel black-box \"knowledge watermark\" approach, named RAG-WM, to detect IP infringement of RAGs. RAG-WM uses a multi-LLM interaction framework, comprising a Watermark Generator, Shadow LLM & RAG, and Watermark Discriminator, to create watermark texts based on watermark entity-relationship tuples and inject them into the target RAG. We evaluate RAG-WM across three domain-specific and two privacy-sensitive tasks on four benchmark LLMs. Experimental results show that RAG-WM effectively detects the stolen RAGs in various deployed LLMs. Furthermore, RAG-WM is robust against paraphrasing, unrelated content removal, knowledge insertion, and knowledge expansion attacks. Lastly, RAG-WM can also evade watermark detection approaches, highlighting its promising application in detecting IP infringement of RAG systems.", "authors": ["Peizhuo Lv", "Mengjie Sun", "Hao Wang", "Xiaofeng Wang", "Shengzhi Zhang", "Yuxuan Chen", "Kai Chen", "Limin Sun"], "published_date": "2025-01-09T14:01:15Z", "url": "http://arxiv.org/abs/2501.05249v1", "pdf_url": "http://arxiv.org/pdf/2501.05249v1", "primary_category": "cs.CR"}
{"doc_id": "2409.01666v1", "title": "In Defense of RAG in the Era of Long-Context Language Models", "abstract": "Overcoming the limited context limitations in early-generation LLMs, retrieval-augmented generation (RAG) has been a reliable solution for context-based answer generation in the past. Recently, the emergence of long-context LLMs allows the models to incorporate much longer text sequences, making RAG less attractive. Recent studies show that long-context LLMs significantly outperform RAG in long-context applications. Unlike the existing works favoring the long-context LLM over RAG, we argue that the extremely long context in LLMs suffers from a diminished focus on relevant information and leads to potential degradation in answer quality. This paper revisits the RAG in long-context answer generation. We propose an order-preserve retrieval-augmented generation (OP-RAG) mechanism, which significantly improves the performance of RAG for long-context question-answer applications. With OP-RAG, as the number of retrieved chunks increases, the answer quality initially rises, and then declines, forming an inverted U-shaped curve. There exist sweet points where OP-RAG could achieve higher answer quality with much less tokens than long-context LLM taking the whole context as input. Extensive experiments on public benchmark demonstrate the superiority of our OP-RAG.", "authors": ["Tan Yu", "Anbang Xu", "Rama Akkiraju"], "published_date": "2024-09-03T07:17:41Z", "url": "http://arxiv.org/abs/2409.01666v1", "pdf_url": "http://arxiv.org/pdf/2409.01666v1", "primary_category": "cs.CL"}
{"doc_id": "2403.09040v3", "title": "RAGGED: Towards Informed Design of Scalable and Stable RAG Systems", "abstract": "Retrieval-augmented generation (RAG) enhances language models by integrating external knowledge, but its effectiveness is highly dependent on system configuration. Improper retrieval settings can degrade performance, making RAG less reliable than closed-book generation. In this work, we introduce RAGGED, a framework for systematically evaluating RAG systems across diverse retriever-reader configurations, retrieval depths, and datasets. Our analysis reveals that reader robustness to noise is the key determinant of RAG stability and scalability. Some readers benefit from increased retrieval depth, while others degrade due to their sensitivity to distracting content. Through large-scale experiments on open-domain, multi-hop, and specialized-domain datasets, we show that retrievers, rerankers, and prompts influence performance but do not fundamentally alter these reader-driven trends. By providing a principled framework and new metrics to assess RAG stability and scalability, RAGGED enables systematic evaluation of retrieval-augmented generation systems, guiding future research on optimizing retrieval depth and model robustness.", "authors": ["Jennifer Hsia", "Afreen Shaikh", "Zhiruo Wang", "Graham Neubig"], "published_date": "2024-03-14T02:26:31Z", "url": "http://arxiv.org/abs/2403.09040v3", "pdf_url": "http://arxiv.org/pdf/2403.09040v3", "primary_category": "cs.CL"}
{"doc_id": "2504.07103v1", "title": "FG-RAG: Enhancing Query-Focused Summarization with Context-Aware   Fine-Grained Graph RAG", "abstract": "Retrieval-Augmented Generation (RAG) enables large language models to provide more precise and pertinent responses by incorporating external knowledge. In the Query-Focused Summarization (QFS) task, GraphRAG-based approaches have notably enhanced the comprehensiveness and diversity of generated responses. However, existing GraphRAG-based approaches predominantly focus on coarse-grained information summarization without being aware of the specific query, and the retrieved content lacks sufficient contextual information to generate comprehensive responses. To address the deficiencies of current RAG systems, we propose Context-Aware Fine-Grained Graph RAG (FG-RAG) to enhance the performance of the QFS task. FG-RAG employs Context-Aware Entity Expansion in graph retrieval to expand the coverage of retrieved entities in the graph, thus providing enough contextual information for the retrieved content. Furthermore, FG-RAG utilizes Query-Level Fine-Grained Summarization to incorporate fine-grained details during response generation, enhancing query awareness for the generated summarization. Our evaluation demonstrates that FG-RAG outperforms other RAG systems in multiple metrics of comprehensiveness, diversity, and empowerment when handling the QFS task. Our implementation is available at https://github.com/BuptWululu/FG-RAG.", "authors": ["Yubin Hong", "Chaofan Li", "Jingyi Zhang", "Yingxia Shao"], "published_date": "2025-03-13T17:42:07Z", "url": "http://arxiv.org/abs/2504.07103v1", "pdf_url": "http://arxiv.org/pdf/2504.07103v1", "primary_category": "cs.IR"}
{"doc_id": "2506.20978v1", "title": "Response Quality Assessment for Retrieval-Augmented Generation via   Conditional Conformal Factuality", "abstract": "Existing research on Retrieval-Augmented Generation (RAG) primarily focuses on improving overall question-answering accuracy, often overlooking the quality of sub-claims within generated responses. Recent methods that attempt to improve RAG trustworthiness, such as through auto-evaluation metrics, lack probabilistic guarantees or require ground truth answers. To address these limitations, we propose Conformal-RAG, a novel framework inspired by recent applications of conformal prediction (CP) on large language models (LLMs). Conformal-RAG leverages CP and internal information from the RAG mechanism to offer statistical guarantees on response quality. It ensures group-conditional coverage spanning multiple sub-domains without requiring manual labelling of conformal sets, making it suitable for complex RAG applications. Compared to existing RAG auto-evaluation methods, Conformal-RAG offers statistical guarantees on the quality of refined sub-claims, ensuring response reliability without the need for ground truth answers. Additionally, our experiments demonstrate that by leveraging information from the RAG system, Conformal-RAG retains up to 60\\% more high-quality sub-claims from the response compared to direct applications of CP to LLMs, while maintaining the same reliability guarantee.", "authors": ["Naihe Feng", "Yi Sui", "Shiyi Hou", "Jesse C. Cresswell", "Ga Wu"], "published_date": "2025-06-26T03:52:56Z", "url": "http://arxiv.org/abs/2506.20978v1", "pdf_url": "http://arxiv.org/pdf/2506.20978v1", "primary_category": "cs.IR"}
{"doc_id": "2401.15391v1", "title": "MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop   Queries", "abstract": "Retrieval-augmented generation (RAG) augments large language models (LLM) by retrieving relevant knowledge, showing promising potential in mitigating LLM hallucinations and enhancing response quality, thereby facilitating the great adoption of LLMs in practice. However, we find that existing RAG systems are inadequate in answering multi-hop queries, which require retrieving and reasoning over multiple pieces of supporting evidence. Furthermore, to our knowledge, no existing RAG benchmarking dataset focuses on multi-hop queries. In this paper, we develop a novel dataset, MultiHop-RAG, which consists of a knowledge base, a large collection of multi-hop queries, their ground-truth answers, and the associated supporting evidence. We detail the procedure of building the dataset, utilizing an English news article dataset as the underlying RAG knowledge base. We demonstrate the benchmarking utility of MultiHop-RAG in two experiments. The first experiment compares different embedding models for retrieving evidence for multi-hop queries. In the second experiment, we examine the capabilities of various state-of-the-art LLMs, including GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop queries given the evidence. Both experiments reveal that existing RAG methods perform unsatisfactorily in retrieving and answering multi-hop queries. We hope MultiHop-RAG will be a valuable resource for the community in developing effective RAG systems, thereby facilitating greater adoption of LLMs in practice. The MultiHop-RAG and implemented RAG system is publicly available at https://github.com/yixuantt/MultiHop-RAG/.", "authors": ["Yixuan Tang", "Yi Yang"], "published_date": "2024-01-27T11:41:48Z", "url": "http://arxiv.org/abs/2401.15391v1", "pdf_url": "http://arxiv.org/pdf/2401.15391v1", "primary_category": "cs.CL"}
{"doc_id": "2507.08862v1", "title": "RAG Safety: Exploring Knowledge Poisoning Attacks to Retrieval-Augmented   Generation", "abstract": "Retrieval-Augmented Generation (RAG) enhances large language models (LLMs) by retrieving external data to mitigate hallucinations and outdated knowledge issues. Benefiting from the strong ability in facilitating diverse data sources and supporting faithful reasoning, knowledge graphs (KGs) have been increasingly adopted in RAG systems, giving rise to KG-based RAG (KG-RAG) methods. Though RAG systems are widely applied in various applications, recent studies have also revealed its vulnerabilities to data poisoning attacks, where malicious information injected into external knowledge sources can mislead the system into producing incorrect or harmful responses. However, these studies focus exclusively on RAG systems using unstructured textual data sources, leaving the security risks of KG-RAG largely unexplored, despite the fact that KGs present unique vulnerabilities due to their structured and editable nature. In this work, we conduct the first systematic investigation of the security issue of KG-RAG methods through data poisoning attacks. To this end, we introduce a practical, stealthy attack setting that aligns with real-world implementation. We propose an attack strategy that first identifies adversarial target answers and then inserts perturbation triples to complete misleading inference chains in the KG, increasing the likelihood that KG-RAG methods retrieve and rely on these perturbations during generation. Through extensive experiments on two benchmarks and four recent KG-RAG methods, our attack strategy demonstrates strong effectiveness in degrading KG-RAG performance, even with minimal KG perturbations. In-depth analyses are also conducted to understand the safety threats within the internal stages of KG-RAG systems and to explore the robustness of LLMs against adversarial knowledge.", "authors": ["Tianzhe Zhao", "Jiaoyan Chen", "Yanchi Ru", "Haiping Zhu", "Nan Hu", "Jun Liu", "Qika Lin"], "published_date": "2025-07-09T13:06:58Z", "url": "http://arxiv.org/abs/2507.08862v1", "pdf_url": "http://arxiv.org/pdf/2507.08862v1", "primary_category": "cs.CR"}
{"doc_id": "2506.10030v1", "title": "Safeguarding Multimodal Knowledge Copyright in the RAG-as-a-Service   Environment", "abstract": "As Retrieval-Augmented Generation (RAG) evolves into service-oriented platforms (Rag-as-a-Service) with shared knowledge bases, protecting the copyright of contributed data becomes essential. Existing watermarking methods in RAG focus solely on textual knowledge, leaving image knowledge unprotected. In this work, we propose AQUA, the first watermark framework for image knowledge protection in Multimodal RAG systems. AQUA embeds semantic signals into synthetic images using two complementary methods: acronym-based triggers and spatial relationship cues. These techniques ensure watermark signals survive indirect watermark propagation from image retriever to textual generator, being efficient, effective and imperceptible. Experiments across diverse models and datasets show that AQUA enables robust, stealthy, and reliable copyright tracing, filling a key gap in multimodal RAG protection.", "authors": ["Tianyu Chen", "Jian Lou", "Wenjie Wang"], "published_date": "2025-06-10T09:56:02Z", "url": "http://arxiv.org/abs/2506.10030v1", "pdf_url": "http://arxiv.org/pdf/2506.10030v1", "primary_category": "cs.CR"}
{"doc_id": "2410.07176v2", "title": "Astute RAG: Overcoming Imperfect Retrieval Augmentation and Knowledge   Conflicts for Large Language Models", "abstract": "Retrieval augmented generation (RAG), while effectively integrating external knowledge to address the inherent limitations of large language models (LLMs), can be hindered by imperfect retrieval that contain irrelevant, misleading, or even malicious information. Previous studies have rarely connected the behavior of RAG through joint analysis, particularly regarding error propagation coming from imperfect retrieval and potential conflicts between LLMs' internal knowledge and external sources. Through comprehensive and controlled analyses under realistic conditions, we find that imperfect retrieval augmentation is inevitable, common, and harmful. We identify the knowledge conflicts between LLM-internal and external knowledge from retrieval as a bottleneck to overcome imperfect retrieval in the post-retrieval stage of RAG. To address this, we propose Astute RAG, a novel RAG approach designed to be resilient to imperfect retrieval augmentation. It adaptively elicits essential information from LLMs' internal knowledge, iteratively consolidates internal and external knowledge with source-awareness, and finalizes the answer according to information reliability. Our experiments with Gemini and Claude demonstrate the superior performance of Astute RAG compared to previous robustness-enhanced RAG approaches. Specifically, Astute RAG is the only RAG method that achieves performance comparable to or even surpassing conventional use of LLMs under the worst-case scenario. Further analysis reveals the effectiveness of Astute RAG in resolving knowledge conflicts, thereby improving the trustworthiness of RAG.", "authors": ["Fei Wang", "Xingchen Wan", "Ruoxi Sun", "Jiefeng Chen", "Sercan \u00d6. Ar\u0131k"], "published_date": "2024-10-09T17:59:58Z", "url": "http://arxiv.org/abs/2410.07176v2", "pdf_url": "http://arxiv.org/pdf/2410.07176v2", "primary_category": "cs.CL"}
{"doc_id": "2410.13509v2", "title": "RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable   Data Rewards", "abstract": "Retrieval-Augmented Generation (RAG) has proven its effectiveness in mitigating hallucinations in Large Language Models (LLMs) by retrieving knowledge from external resources. To adapt LLMs for the RAG systems, current approaches use instruction tuning to optimize LLMs, improving their ability to utilize retrieved knowledge. This supervised fine-tuning (SFT) approach focuses on equipping LLMs to handle diverse RAG tasks using different instructions. However, it trains RAG modules to overfit training signals and overlooks the varying data preferences among agents within the RAG system. In this paper, we propose a Differentiable Data Rewards (DDR) method, which end-to-end trains RAG systems by aligning data preferences between different RAG modules. DDR works by collecting the rewards to optimize each agent in the RAG system with the rollout method, which prompts agents to sample some potential responses as perturbations, evaluates the impact of these perturbations on the whole RAG system, and subsequently optimizes the agent to produce outputs that improve the performance of the RAG system. Our experiments on various knowledge-intensive tasks demonstrate that DDR significantly outperforms the SFT method, particularly for LLMs with smaller-scale parameters that depend more on the retrieved knowledge. Additionally, DDR exhibits a stronger capability to align the data preference between RAG modules. The DDR method makes the generation module more effective in extracting key information from documents and mitigating conflicts between parametric memory and external knowledge. All codes are available at https://github.com/OpenMatch/RAG-DDR.", "authors": ["Xinze Li", "Sen Mei", "Zhenghao Liu", "Yukun Yan", "Shuo Wang", "Shi Yu", "Zheni Zeng", "Hao Chen", "Ge Yu", "Zhiyuan Liu", "Maosong Sun", "Chenyan Xiong"], "published_date": "2024-10-17T12:53:29Z", "url": "http://arxiv.org/abs/2410.13509v2", "pdf_url": "http://arxiv.org/pdf/2410.13509v2", "primary_category": "cs.CL"}
{"doc_id": "2401.05856v1", "title": "Seven Failure Points When Engineering a Retrieval Augmented Generation   System", "abstract": "Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.", "authors": ["Scott Barnett", "Stefanus Kurniawan", "Srikanth Thudumu", "Zach Brannelly", "Mohamed Abdelrazek"], "published_date": "2024-01-11T12:04:11Z", "url": "http://arxiv.org/abs/2401.05856v1", "pdf_url": "http://arxiv.org/pdf/2401.05856v1", "primary_category": "cs.SE"}
{"doc_id": "2404.00657v1", "title": "Observations on Building RAG Systems for Technical Documents", "abstract": "Retrieval augmented generation (RAG) for technical documents creates challenges as embeddings do not often capture domain information. We review prior art for important factors affecting RAG and perform experiments to highlight best practices and potential challenges to build RAG systems for technical documents.", "authors": ["Sumit Soman", "Sujoy Roychowdhury"], "published_date": "2024-03-31T12:01:34Z", "url": "http://arxiv.org/abs/2404.00657v1", "pdf_url": "http://arxiv.org/pdf/2404.00657v1", "primary_category": "cs.LG"}
{"doc_id": "2408.02545v1", "title": "RAG Foundry: A Framework for Enhancing LLMs for Retrieval Augmented   Generation", "abstract": "Implementing Retrieval-Augmented Generation (RAG) systems is inherently complex, requiring deep understanding of data, use cases, and intricate design decisions. Additionally, evaluating these systems presents significant challenges, necessitating assessment of both retrieval accuracy and generative quality through a multi-faceted approach. We introduce RAG Foundry, an open-source framework for augmenting large language models for RAG use cases. RAG Foundry integrates data creation, training, inference and evaluation into a single workflow, facilitating the creation of data-augmented datasets for training and evaluating large language models in RAG settings. This integration enables rapid prototyping and experimentation with various RAG techniques, allowing users to easily generate datasets and train RAG models using internal or specialized knowledge sources. We demonstrate the framework effectiveness by augmenting and fine-tuning Llama-3 and Phi-3 models with diverse RAG configurations, showcasing consistent improvements across three knowledge-intensive datasets. Code is released as open-source in https://github.com/IntelLabs/RAGFoundry.", "authors": ["Daniel Fleischer", "Moshe Berchansky", "Moshe Wasserblat", "Peter Izsak"], "published_date": "2024-08-05T15:16:24Z", "url": "http://arxiv.org/abs/2408.02545v1", "pdf_url": "http://arxiv.org/pdf/2408.02545v1", "primary_category": "cs.CL"}
{"doc_id": "2410.20753v2", "title": "Plan*RAG: Efficient Test-Time Planning for Retrieval Augmented   Generation", "abstract": "We introduce Plan*RAG, a novel framework that enables structured multi-hop reasoning in retrieval-augmented generation (RAG) through test-time reasoning plan generation. While existing approaches such as ReAct maintain reasoning chains within the language model's context window, we observe that this often leads to plan fragmentation and execution failures. Our key insight is that by isolating the reasoning plan as a directed acyclic graph (DAG) outside the LM's working memory, we can enable (1) systematic exploration of reasoning paths, (2) atomic subqueries enabling precise retrievals and grounding, and (3) efficiency through parallel execution and bounded context window utilization. Moreover, Plan*RAG's modular design allows it to be integrated with existing RAG methods, thus providing a practical solution to improve current RAG systems. On standard multi-hop reasoning benchmarks, Plan*RAG consistently achieves improvements over recently proposed methods such as RQ-RAG and Self-RAG, while maintaining comparable computational costs.", "authors": ["Prakhar Verma", "Sukruta Prakash Midigeshi", "Gaurav Sinha", "Arno Solin", "Nagarajan Natarajan", "Amit Sharma"], "published_date": "2024-10-28T05:35:04Z", "url": "http://arxiv.org/abs/2410.20753v2", "pdf_url": "http://arxiv.org/pdf/2410.20753v2", "primary_category": "cs.CL"}
{"doc_id": "2412.10543v2", "title": "METIS: Fast Quality-Aware RAG Systems with Configuration Adaptation", "abstract": "RAG (Retrieval Augmented Generation) allows LLMs (large language models) to generate better responses with external knowledge, but using more external knowledge often improves generation quality at the expense of response delay. Prior work either reduces the response delay (through better scheduling of RAG queries) or strives to maximize quality (which involves tuning the RAG workflow), but they fall short in optimizing the tradeoff between the delay and quality of RAG responses. This paper presents METIS, the first RAG system that jointly schedules queries and adapts the key RAG configurations of each query, such as the number of retrieved text chunks and synthesis methods, in order to balance quality optimization and response delay reduction. Using 4 popular RAG-QA datasets, we show that compared with the state-of-the-art RAG optimization schemes, METIS reduces the generation latency by $1.64-2.54\\times$ without sacrificing generation quality.", "authors": ["Siddhant Ray", "Rui Pan", "Zhuohan Gu", "Kuntai Du", "Shaoting Feng", "Ganesh Ananthanarayanan", "Ravi Netravali", "Junchen Jiang"], "published_date": "2024-12-13T20:39:30Z", "url": "http://arxiv.org/abs/2412.10543v2", "pdf_url": "http://arxiv.org/pdf/2412.10543v2", "primary_category": "cs.LG"}
